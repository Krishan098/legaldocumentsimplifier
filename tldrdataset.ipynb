{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question_id', 'nl', 'cmd', 'oracle_man', 'cmd_name', 'tldr_cmd_name', 'manual_exist', 'matching_info'],\n",
      "        num_rows: 6414\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question_id', 'nl', 'cmd', 'oracle_man', 'cmd_name', 'tldr_cmd_name', 'manual_exist', 'matching_info'],\n",
      "        num_rows: 928\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['question_id', 'nl', 'cmd', 'oracle_man', 'cmd_name', 'tldr_cmd_name', 'manual_exist', 'matching_info'],\n",
      "        num_rows: 1845\n",
      "    })\n",
      "})\n",
      "{'question_id': '0', 'nl': 'get the label of a fat32 partition', 'cmd': 'fatlabel {{/dev/sda1}}', 'oracle_man': ['fatlabel_3'], 'cmd_name': 'fatlabel', 'tldr_cmd_name': 'fatlabel', 'manual_exist': True, 'matching_info': {'token': ['|main|'], 'oracle_man': [['fatlabel_3', 'fatlabel_4']]}}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the TLDR dataset with remote code execution allowed\n",
    "tldr = load_dataset('neulab/tldr', trust_remote_code=True)\n",
    "\n",
    "# Access the dataset splits\n",
    "tldr_train = tldr['train']\n",
    "tldr_validation = tldr['validation']  # Check if 'validation' is available\n",
    "tldr_test = tldr['test']\n",
    "\n",
    "# Inspect the dataset structure (optional)\n",
    "print(tldr)\n",
    "print(tldr_train[0])  # Print the first example from the training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples = tldr['test'].select(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original NL Description: delete a shared memory segment by id\n",
      "\n",
      "Generated Summary (Command): delete a shared memory segment by id by id or by id in the following manner: (i.e. delete a memory segment from the shared memory of a person who has shared a memory with another person): (1) delete a segment from a memory that is\n",
      "\n",
      "Reference Summary (Command): ipcrm --shmem-id {{shmem_id}}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Original NL Description: delete a shared memory segment by key\n",
      "\n",
      "Generated Summary (Command): delete a shared memory segment by key key by key by deleting a key from a key in a key memory segment and replacing it with a new key by a different key in the same key. delete a key and replace it with another key by another key.delete a\n",
      "\n",
      "Reference Summary (Command): ipcrm --shmem-key {{shmem_key}}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Original NL Description: delete an ipc queue by id\n",
      "\n",
      "Generated Summary (Command): delete an ipc queue by id by id to avoid the use of the id of an IPc queue on a computer with an id that is not the same as the id used to create the queue by the user's IP address.delete an IPC queue by\n",
      "\n",
      "Reference Summary (Command): ipcrm --queue-id {{ipc_queue_id}}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Original NL Description: delete an ipc queue by key\n",
      "\n",
      "Generated Summary (Command): delete an ipc queue by key by key: (i.e. delete an IPc queue from an address by key or a key from a key to a key that is not a key) to an address that is a key or an address in a key\n",
      "\n",
      "Reference Summary (Command): ipcrm --queue-key {{ipc_queue_key}}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Original NL Description: delete a semaphore by id\n",
      "\n",
      "Generated Summary (Command): delete a semaphore by id by id or by id to avoid the use of semaphores by the user of a mobile phone or other mobile device in the U.S. or any other country in the world in which such a device is used.\n",
      "\n",
      "Reference Summary (Command): ipcrm --semaphore-id {{semaphore_id}}\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "generated_summaries = []\n",
    "reference_summaries = []\n",
    "\n",
    "# Define maximum lengths for source and target text\n",
    "MAX_SOURCE_LENGTH = 512  # Maximum length of input text (e.g., 'nl')\n",
    "MAX_TARGET_LENGTH = 64   # Maximum length of the generated summary (e.g., 'cmd')\n",
    "\n",
    "\n",
    "# Ensure the model and tokenizer are moved to the correct device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Loop through the TLDR test examples\n",
    "with torch.no_grad():\n",
    "    for example in test_examples:\n",
    "        # Use the 'nl' field as the input text\n",
    "        inputs = tokenizer(\n",
    "            example['nl'],  # Input: natural language description\n",
    "            max_length=MAX_SOURCE_LENGTH,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # Generate summary\n",
    "        summary_ids = model.generate(\n",
    "            inputs['input_ids'],\n",
    "            num_beams=4,\n",
    "            max_length=MAX_TARGET_LENGTH,\n",
    "            length_penalty=2.0,\n",
    "            early_stopping=True,\n",
    "            no_repeat_ngram_size=3\n",
    "        )\n",
    "\n",
    "        # Decode generated summary\n",
    "        generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        generated_summaries.append(generated_summary)\n",
    "\n",
    "        # Use the 'cmd' field as the reference summary\n",
    "        reference_summaries.append(example['cmd'])\n",
    "\n",
    "        # Print results\n",
    "        print(\"\\nOriginal NL Description:\", example['nl'])\n",
    "        print(\"\\nGenerated Summary (Command):\", generated_summary)\n",
    "        print(\"\\nReference Summary (Command):\", example['cmd'])\n",
    "        print(\"\\n\" + \"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average ROUGE Scores:\n",
      "rouge1: 0.1368\n",
      "rouge2: 0.0155\n",
      "rougeL: 0.1288\n",
      "\n",
      "Average Flesch-Kincaid Grade Level (FKGL): 8.0600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'generated_summaries': ['delete a shared memory segment by id by id or by id in the following manner: (i.e. delete a memory segment from the shared memory of a person who has shared a memory with another person): (1) delete a segment from a memory that is',\n",
       "  'delete a shared memory segment by key key by key by deleting a key from a key in a key memory segment and replacing it with a new key by a different key in the same key. delete a key and replace it with another key by another key.delete a',\n",
       "  \"delete an ipc queue by id by id to avoid the use of the id of an IPc queue on a computer with an id that is not the same as the id used to create the queue by the user's IP address.delete an IPC queue by\",\n",
       "  'delete an ipc queue by key by key: (i.e. delete an IPc queue from an address by key or a key from a key to a key that is not a key) to an address that is a key or an address in a key',\n",
       "  'delete a semaphore by id by id or by id to avoid the use of semaphores by the user of a mobile phone or other mobile device in the U.S. or any other country in the world in which such a device is used.'],\n",
       " 'reference_summaries': ['ipcrm --shmem-id {{shmem_id}}',\n",
       "  'ipcrm --shmem-key {{shmem_key}}',\n",
       "  'ipcrm --queue-id {{ipc_queue_id}}',\n",
       "  'ipcrm --queue-key {{ipc_queue_key}}',\n",
       "  'ipcrm --semaphore-id {{semaphore_id}}'],\n",
       " 'rouge_scores': {'rouge1': 0.136797163620693,\n",
       "  'rouge2': 0.015547169811320755,\n",
       "  'rougeL': 0.12879716362069302},\n",
       " 'fkgl_scores': [9.7, 9.5, 6.6, 6.2, 8.3],\n",
       " 'avg_fkgl_score': 8.059999999999999}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from rouge_score import rouge_scorer\n",
    "import numpy as np\n",
    "import textstat  # Library for readability scores\n",
    "\n",
    "# Define the ROUGE scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "# Define the Flesch-Kincaid Grade Level (FKGL) scorer\n",
    "def calculate_fkgl(text):\n",
    "    return textstat.flesch_kincaid_grade(text)\n",
    "\n",
    "# List to hold the ROUGE scores and FKGL scores for each example\n",
    "rouge_scores = []\n",
    "fkgl_scores = []\n",
    "\n",
    "# Loop through the generated and reference summaries\n",
    "for gen, ref in zip(generated_summaries, reference_summaries):\n",
    "    # ROUGE scoring\n",
    "    score = scorer.score(gen, ref)\n",
    "    rouge_scores.append(score)\n",
    "\n",
    "    # FKGL scoring for the generated summary\n",
    "    fkgl_score = calculate_fkgl(gen)\n",
    "    fkgl_scores.append(fkgl_score)\n",
    "\n",
    "# Compute the average ROUGE scores\n",
    "avg_rouge_scores = {\n",
    "    'rouge1': np.mean([score['rouge1'].fmeasure for score in rouge_scores]),\n",
    "    'rouge2': np.mean([score['rouge2'].fmeasure for score in rouge_scores]),\n",
    "    'rougeL': np.mean([score['rougeL'].fmeasure for score in rouge_scores])\n",
    "}\n",
    "\n",
    "# Compute the average FKGL score\n",
    "avg_fkgl_score = np.mean(fkgl_scores)\n",
    "\n",
    "# Print the average ROUGE scores and FKGL score\n",
    "print(\"\\nAverage ROUGE Scores:\")\n",
    "for metric, score in avg_rouge_scores.items():\n",
    "    print(f\"{metric}: {score:.4f}\")\n",
    "\n",
    "print(f\"\\nAverage Flesch-Kincaid Grade Level (FKGL): {avg_fkgl_score:.4f}\")\n",
    "\n",
    "# Prepare the summary results\n",
    "summary_results = {\n",
    "    'generated_summaries': generated_summaries,\n",
    "    'reference_summaries': reference_summaries,\n",
    "    'rouge_scores': avg_rouge_scores,\n",
    "    'fkgl_scores': fkgl_scores,\n",
    "    'avg_fkgl_score': avg_fkgl_score\n",
    "}\n",
    "\n",
    "# Display or return the summary results\n",
    "summary_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
